\chapter{Introduction}
A liga de Simulação de Futebol 2D da \cite{robocup} (Sim2d) é uma das mais antigas da competição, tendo início em 1996. As técnicas mais usadas nos 5 melhores times da liga são Aprendizagem Supervisionada e Algorítmos determinísticos. Pesquisas recentes  tem mostrado que usar Aprendizagem Profunda por Reforço (APR) para treinar agentes autônomos em sistemas multi agentes se obtém uma performance maior. O time CYRUS2019, \cite{cyrus}, fez sua linha defensiva de jogadores usando APR e conquistou o terceiro lugar na RoboCup2019.Este trabalho pretende incluir uma linha de defesa treinada com uma técnica de APR baseado no time CYRUS2019, adpatando o ambiente do \textit{Half Field Offensive} para um ambiente OpenAI GYM, \cite{gym}, e aplicar ao time da equipe \cite{robocin}.

Com o objetivo de vencer o time capeão mundial humano de 2050, a RoboCup tem sido uma grande competição para desenvolver e compartilhar técnicas sobre robótica e agentes autônomos. Entre as ligas, Simulação de Futebol 2D é um dos melhores ambientes para se aplicar algoritmos de aprend
With the goal of beating the human soccer World Champion team in 2050, Robocup has been a great competition to develop and share robotics and autonomous agents techniques. Among the leagues, Soccer Simulation 2D league is a great domain to invest machine learning (ML) algorithms and it is been a challenge as \cite{RoboCupAIChallenge} say. At the very beginning of the league at 1996, the competitors used to implement by their own hands the behaviours of the players. Once it's a simulated league, Machine Learning techniques became natural since there is no mechanic or electronic interference. The German team, Brainstormers was one of the pilots with an approach using Reinforcement Learning (\cite{brainstormers2002}). Since then teams frequently uses Artificial Intelligence algorithms to have unnatural and unpredictable behaviours. 

This work focus on the defense line, specifically in a single intelligent defender cooperating with a hand-coded goalie against a single attacker. As there is more works about the attackers like \cite{passingCrit}, \cite{keepawayRL} and more recent \cite{hausknecht2015deep}, the defense line became attractive to the RoboCIn team.

\cite{deepmind} researchers \cite{dqn} have shown that Deep Q Learning was so effective on Atari games that it outplays human controlled agents. In 2015 Deepmind's AlphaGo agent, \cite{alphago}, won from the European Go Champion Fan Hui and later on 2016 from Lee Sedol, one of the best worldwide. Since then OpenAI and DeepMind has invested a lot of effort on Reinforcement Learning (RL) and Autonomous Agents (AA) systems. Recently \cite{openai5} has become the best agent on \cite{dota2} on 1v1 games and it has a great teamwork performance on 5v5 games winning from most of amateur teams and a few professionals.

Inspired by those recent researches \cite{cyrus} modeled a defensive autonomous agent and it has almost the same efficiency of the champions' Fractals (\cite{glidersv2}, and Helios, \cite{helios2016}, defenses. Based on \cite{cyrus} work we will compare three Deep Reinforcement Learning models, \cite{dqn}, \cite{DDQN}, \cite{DDPG}, applied to an environment very likely to the real Soccer Simulation 2D.
