\chapter{Objectives}
The main objective of this work is to analyze the performance of three DRL algorithms on RoboCup's Simulation 2D environment. Deep Q Network (DQN), \cite{dqn}, Dueling Double Q Network (DDQN), \cite{DDQN}, and Deep Deterministic Policy Gradients (DDPG), \cite{DDPG}, algorithms were chosen to be compared. This choice was based on \cite{cyrus} work which applied DDPG on it's defensive agents.

Before the train and test of the algorithms all the environment has to be set doing the following minors objectives:
\begin{itemize}
    \item Adapt HFO server to our context.
    \item Prepare the environment to be like OpenAI GYM.
    \item Choose the features to use on the NNs.
    \item Creation of RoboCin's biased dataset without PER.
    \item Creation of RoboCin's biased dataset with PER.
\end{itemize}